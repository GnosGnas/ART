{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cuda_nsm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na4y0ETwXtzh"
      },
      "outputs": [],
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.geeksforgeeks.org/how-to-run-cuda-c-c-on-jupyter-notebook-in-google-colaboratory/\n",
        "\n",
        "TO RUN CUDA C ON COLAB\n"
      ],
      "metadata": {
        "id": "736XdVgIXwzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "metadata": {
        "id": "QC9MQfq_YPTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v-zpN0OYXfJ",
        "outputId": "aba84754-fc23-48f9-e9ec-f39e6957e972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "K0Wk4_6IYcVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GeAsXcuYegs",
        "outputId": "b2cec006-3ce7-4b3c-968c-ecbb248c43cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frLHAEORapx4",
        "outputId": "ea4d6470-c189-49c0-903b-4304a07dc050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 10:03:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "__global__ void func()\n",
        "{\n",
        "\t\tuint block_id = blockIdx.x;\n",
        "\t\tuint thread_id = threadIdx.x;\n",
        "\t\tint warp_size = warpSize;\n",
        "\t\tdim3 grids = gridDim; //number of blocks in each dimension\n",
        "\t\tuint block_dim = blockDim.y; //dimensions of block\n",
        "\t \n",
        "\t\tprintf(\"Hola dev%u %u %d %d %d\\n\", block_id, thread_id, warp_size, grids.y, block_dim);\n",
        "}\n",
        "\n",
        "int\tmain()\n",
        "{\n",
        "\tfunc<<<10,5>>>();\n",
        "\tcudaDeviceSynchronize();\n",
        "\tstd::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88UeB6yYiWs",
        "outputId": "e32d31cf-3e14-4b92-bb54-c190577942e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola dev9 0 32 1 1\n",
            "Hola dev9 1 32 1 1\n",
            "Hola dev9 2 32 1 1\n",
            "Hola dev9 3 32 1 1\n",
            "Hola dev9 4 32 1 1\n",
            "Hola dev8 0 32 1 1\n",
            "Hola dev8 1 32 1 1\n",
            "Hola dev8 2 32 1 1\n",
            "Hola dev8 3 32 1 1\n",
            "Hola dev8 4 32 1 1\n",
            "Hola dev6 0 32 1 1\n",
            "Hola dev6 1 32 1 1\n",
            "Hola dev6 2 32 1 1\n",
            "Hola dev6 3 32 1 1\n",
            "Hola dev6 4 32 1 1\n",
            "Hola dev4 0 32 1 1\n",
            "Hola dev4 1 32 1 1\n",
            "Hola dev4 2 32 1 1\n",
            "Hola dev4 3 32 1 1\n",
            "Hola dev4 4 32 1 1\n",
            "Hola dev3 0 32 1 1\n",
            "Hola dev3 1 32 1 1\n",
            "Hola dev3 2 32 1 1\n",
            "Hola dev3 3 32 1 1\n",
            "Hola dev3 4 32 1 1\n",
            "Hola dev1 0 32 1 1\n",
            "Hola dev1 1 32 1 1\n",
            "Hola dev1 2 32 1 1\n",
            "Hola dev1 3 32 1 1\n",
            "Hola dev1 4 32 1 1\n",
            "Hola dev7 0 32 1 1\n",
            "Hola dev7 1 32 1 1\n",
            "Hola dev7 2 32 1 1\n",
            "Hola dev7 3 32 1 1\n",
            "Hola dev7 4 32 1 1\n",
            "Hola dev0 0 32 1 1\n",
            "Hola dev0 1 32 1 1\n",
            "Hola dev0 2 32 1 1\n",
            "Hola dev0 3 32 1 1\n",
            "Hola dev0 4 32 1 1\n",
            "Hola dev5 0 32 1 1\n",
            "Hola dev5 1 32 1 1\n",
            "Hola dev5 2 32 1 1\n",
            "Hola dev5 3 32 1 1\n",
            "Hola dev5 4 32 1 1\n",
            "Hola dev2 0 32 1 1\n",
            "Hola dev2 1 32 1 1\n",
            "Hola dev2 2 32 1 1\n",
            "Hola dev2 3 32 1 1\n",
            "Hola dev2 4 32 1 1\n",
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void compute(float *x, float *y, float *z, float a) {\n",
        "  int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  z[tid] = a*x[tid]+y[tid];\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int N = 1024*1024;\n",
        "  float *d_x, *d_y, *d_z;\n",
        "  float a;\n",
        "  size_t size = N * sizeof(float);\n",
        "  float *x = (float*)malloc(size);\n",
        "  float *y = (float*)malloc(size);\n",
        "  float *z = (float*)malloc(size);\n",
        "  \n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        " \n",
        "  cudaMalloc((void**)&d_x, size);\n",
        "  cudaMalloc((void**)&d_y, size);\n",
        "  cudaMalloc((void**)&d_z, size);\n",
        "\n",
        "  for (int k=0; k<N; k++) {\n",
        "    x[k] = 0.5;\n",
        "    y[k] = 1.0;\n",
        "  }\n",
        "  \n",
        "  cudaEventRecord(start); //timer started before copying into memory\n",
        "  \n",
        "  cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  a = 10.1;\n",
        "\n",
        "  int block_size = (int) 1024;\n",
        "  int thread_size = (int) 1024;\n",
        "  \n",
        "  //Timer can be added here too to see time taken to compute\n",
        "  compute<<<block_size, thread_size>>>(x, y, z, a);\n",
        "\n",
        "  cudaMemcpy(z, d_z, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaEventRecord(stop); //timer ended after copying into memory\n",
        "\n",
        "  float milliseconds = 0;\n",
        "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "  for (int i = 0; i < N; i++)  {\n",
        "      //printf(\"%d - %f\\n\", i, z[i]);\n",
        "  }\n",
        "  \n",
        "  printf(\"Execution Time %f \\n\", milliseconds);  \n",
        "  cudaFree(d_x);\n",
        "  cudaFree(d_y);\n",
        "  cudaFree(d_z);\n",
        "  free(x);\n",
        "  free(y);\n",
        "  free(z);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ITrUHEkb3il",
        "outputId": "53315156-46fb-43a2-dd3d-706519cf0e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
